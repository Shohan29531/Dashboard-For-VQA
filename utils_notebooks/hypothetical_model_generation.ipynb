{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e73717-3f16-4b3c-9352-efd58fa8042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import lpips\n",
    "import math\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import cg\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image as Image_openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl.drawing.xdr import XDRPositiveSize2D\n",
    "from openpyxl.utils.units import pixels_to_EMU, cm_to_EMU\n",
    "from openpyxl.drawing.spreadsheet_drawing import OneCellAnchor, AnchorMarker\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fa27cc-57d6-4fad-81d2-87a2087c7ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "loss_fn_vgg = lpips.LPIPS(net='vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86412fa0-2648-4c19-9a46-c236871bb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "transform_f = transforms.ToTensor()\n",
    "\n",
    "def normalize_image(in_img):\n",
    "    pixels = np.asarray(in_img).astype('float32')\n",
    "    pixels = (pixels - mean) / std\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5a33cd-afb2-461f-921c-00724394b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_frame_count = -1\n",
    "ROOT = os.path.abspath(os.path.join(os.curdir, '../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c985e83-abbb-4695-b4de-88ed821268fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = os.path.join(ROOT, 'Dashboard Data/Images')\n",
    "data_path = os.path.join(ROOT, 'Dashboard Data')\n",
    "gt_fol = os.path.join(data_path, \"GT_N\")\n",
    "avg_typ = 'micro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "083e4c5a-5b95-41c7-98f9-14e994a4816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_list = [\n",
    "    \"Accent Paving\", \"Barrier Post\", \"Barrier Stump\", \"Bench\", \"Bicycle\", \"Bridge\", \n",
    "    \"Building\", \"Bus\", \"Bus Stop\", \"Car\", \"Chair\", \"Closed Sidewalk\", \"Counter\", \n",
    "    \"Crosswalk\", \"Curb\", \"Dog\", \"Driveway(flat)\", \"Elevator\", \"Escalator\", \"Fence\", \n",
    "    \"Fire hydrant\", \"Flush Door\", \"Foldout Sign\", \"Fountain\", \"Gate\", \"Guide dog\", \n",
    "    \"Gutter\", \"Hose\", \"Lamp Post\", \"Mail box\", \"Maintenance Vehicle\", \"Motorcycle\", \n",
    "    \"Parallel Parking Spot\", \"Paratransit vehicle\", \"Pedestrian Crossing\", \"Person\", \n",
    "    \"Person with a disability\", \"Pillar\", \"Pole\", \"Puddle\", \"Push button\", \"Railing\", \n",
    "    \"Raised Entryway\", \"Retaining Wall\", \"Road\", \"Road Divider\", \"Road Shoulder\", \n",
    "    \"Roadside Parking\", \"Sidewalk\", \"Sidewalk pits\", \"Sign\", \"Sign Post\", \"Sloped Driveway\", \n",
    "    \"Slopped Curb\", \"Snow\", \"Stairs\", \"Stop sign\", \"Street Vendor\", \"Table\", \"Tactile Paving\", \n",
    "    \"Traffic Signals\", \"Train Platform\", \"Train Tracks\", \"Trash bins\", \"Trash on roads\", \"Tree\", \n",
    "    \"Turnstile\", \"Uncontrolled Crossing\", \"Uneven Stairs\", \"Unpaved Road\", \"Unpaved Sidewalk\", \n",
    "    \"Vegetation\", \"Wall\", \"Water leakage\", \"Water Pipes\", \"Wet surface\", \"Wheelchair\", \n",
    "    \"White Cane\", \"Yard Waste\"\n",
    "]\n",
    "object_list = [ooo.lower() for ooo in object_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a073cd40-c886-42a3-9989-db852a7a34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_ap_ar_af1(gt_path, gt_files, pred_path, obj_list=None):\n",
    "    gt_dict = {}\n",
    "    pred_dict = {}\n",
    "\n",
    "    for fl in gt_files:\n",
    "        if fl in [\"video-10-segment-1.csv\", \"video-9-segment-2.csv\"]:\n",
    "            continue\n",
    "        gt_fl = os.path.join(gt_path, fl)\n",
    "        pred_fl = os.path.join(pred_path, fl)\n",
    "\n",
    "        if not os.path.exists(pred_fl):\n",
    "            continue\n",
    "\n",
    "        if obj_list:\n",
    "            gt_data = pd.read_csv(gt_fl)\n",
    "            if limit_frame_count > 0:\n",
    "                if len(list(gt_data.columns)) > limit_frame_count:\n",
    "                    gt_data = gt_data.iloc[: , :limit_frame_count]\n",
    "\n",
    "            gt_data = gt_data.transpose()\n",
    "            gt_data.columns = [x__.lower() for x__ in gt_data.iloc[0]]\n",
    "            gt_data = gt_data.reindex(columns=obj_list).iloc[1:].transpose().reset_index()\n",
    "\n",
    "            pred_data = pd.read_csv(pred_fl)\n",
    "            if limit_frame_count > 0:\n",
    "                if len(list(pred_data.columns)) > limit_frame_count:\n",
    "                    pred_data = pred_data.iloc[: , :limit_frame_count]\n",
    "\n",
    "            pred_data = pred_data.transpose()\n",
    "            pred_data.columns = [x__.lower() for x__ in pred_data.iloc[0]]\n",
    "            pred_data = pred_data.reindex(columns=obj_list).iloc[1:].transpose().reset_index()    \n",
    "            print(pred_data.isnull().values.any())\n",
    "            # print(gt_data)\n",
    "            # print(pred_data)\n",
    "        else:\n",
    "            gt_data = pd.read_csv(gt_fl)\n",
    "            if limit_frame_count > 0:\n",
    "                if len(list(gt_data.columns)) > limit_frame_count:\n",
    "                    gt_data = gt_data.iloc[: , :limit_frame_count]\n",
    "            gt_data.replace(-1, 1, inplace=True)\n",
    "            pred_data = pd.read_csv(pred_fl)\n",
    "            if limit_frame_count > 0:\n",
    "                if len(list(pred_data.columns)) > limit_frame_count:\n",
    "                    pred_data = pred_data.iloc[: , :limit_frame_count]\n",
    "            pred_data.replace(-1, 1, inplace=True)\n",
    "        \n",
    "        x = []\n",
    "        for index, row in gt_data.iterrows():\n",
    "            # if list(row)[0].strip().lower() in [\"Sidewalk pits\"]:\n",
    "            #     continue\n",
    "            if list(row)[0].strip().lower() in gt_dict.keys():\n",
    "                gt_dict[list(row)[0].strip().lower()] += list(row)[1:]\n",
    "            else:\n",
    "                gt_dict[list(row)[0].strip().lower()] = list(row)[1:]\n",
    "\n",
    "            x.append(len(list(row)[1:]))\n",
    "\n",
    "        y = []\n",
    "        for index, row in pred_data.iterrows():\n",
    "            # if list(row)[0].strip().lower() in [\"Sidewalk pits\"]:\n",
    "            #     continue\n",
    "            if list(row)[0].strip().lower() in pred_dict.keys():\n",
    "                pred_dict[list(row)[0].strip().lower()] += list(row)[1:]\n",
    "            else:\n",
    "                pred_dict[list(row)[0].strip().lower()] = list(row)[1:]\n",
    "            y.append(len(list(row)[1:]))\n",
    "\n",
    "        if x != y:\n",
    "            print(len(x), len(y), fl)\n",
    "\n",
    "    target_array = []\n",
    "    pred_array = []\n",
    "\n",
    "    label_names = []\n",
    "\n",
    "    for key in gt_dict.keys():\n",
    "        if key in pred_dict.keys():\n",
    "            if obj_list:\n",
    "                if key not in obj_list:\n",
    "                    continue\n",
    "            if len(gt_dict[key]) == len(pred_dict[key]):\n",
    "                target_array.append(gt_dict[key])\n",
    "                pred_array.append(pred_dict[key])\n",
    "                label_names.append(key)\n",
    "            else:\n",
    "                print(len(gt_dict[key]), len(pred_dict[key]), key)\n",
    "    \n",
    "    target_array = np.array(target_array).T\n",
    "    pred_array = np.array(pred_array).T\n",
    "\n",
    "    # print(target_array.shape)\n",
    "\n",
    "    # try:\n",
    "    if pred_path.endswith('GT_N'):\n",
    "        precs = precision_score(target_array, pred_array, average=avg_typ)\n",
    "        recs = recall_score(target_array, pred_array, average=avg_typ)\n",
    "        f1ss = f1_score(target_array, pred_array, average=avg_typ)\n",
    "    else:\n",
    "        precs = precision_score(target_array, pred_array, average=avg_typ)\n",
    "        recs = recall_score(target_array, pred_array, average=avg_typ)\n",
    "        f1ss = f1_score(target_array, pred_array, average=avg_typ)\n",
    "    # except Exception as e:\n",
    "    #     # ap = 0\n",
    "    #     print(e)\n",
    "    #     precs = 0.0\n",
    "    #     recs = 0.0\n",
    "    #     f1ss = 0.0\n",
    "\n",
    "    frm_wise_pn_s = (2*target_array) - pred_array\n",
    "\n",
    "    return precs, recs, f1ss, frm_wise_pn_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b60a001-13fc-47cb-8802-bd30d8fd06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_score(img_dir, vid_n, seg_n):\n",
    "    images = natsorted(glob.glob(\n",
    "        os.path.join(\n",
    "            images_dir,\n",
    "            f'video-{vid_n}-segment-{seg_n}-frame*'\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    d_s = {}\n",
    "    \n",
    "    for f in range(1, len(images)):\n",
    "        f_now_pth = images[f]\n",
    "        f_prev_pth = images[f-1]\n",
    "\n",
    "        frm0, frm1 = (os.path.basename(f_prev_pth).split('-')[-1].split('.')[0], \n",
    "                      os.path.basename(f_now_pth).split('-')[-1].split('.')[0])\n",
    "\n",
    "        image_now = cv2.resize(normalize_image(np.array(Image.open(\n",
    "            f_now_pth\n",
    "        ).convert('RGB'))/255), (64, 64), interpolation = cv2.INTER_LINEAR).astype(np.float32)\n",
    "        image_prev = cv2.resize(normalize_image(np.array(Image.open(\n",
    "            f_prev_pth\n",
    "        ).convert('RGB'))/255), (64, 64), interpolation = cv2.INTER_LINEAR).astype(np.float32)\n",
    "\n",
    "        img0 = transform_f(image_now).unsqueeze(0)\n",
    "        img1 = transform_f(image_prev).unsqueeze(0)\n",
    "\n",
    "        d = loss_fn_alex(img0, img1).detach().numpy()[0,0,0,0]\n",
    "\n",
    "        d_s[f'{frm0}-{frm1}'] = d\n",
    "    return d_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2a4fb2-2922-409b-9760-312dae34c820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "coco_common_obj = ['person', 'bicycle', 'car', 'motorcycle', 'bus', 'traffic signals', 'fire hydrant', 'stop sign',\n",
    "                   'bench', 'dog', 'chair', 'vegetation']\n",
    "\n",
    "pfb_common_obj = ['road', 'sidewalk', 'tree', 'vegetation', 'building', 'fence', 'traffic signals',\n",
    "                  'fire hydrant', 'chair', 'trash on roads', 'trash bins', 'person', 'car', 'motorcycle',\n",
    "                  'bus']\n",
    "\n",
    "ram_obj_map = {                   \n",
    "    'chair': 'chair',\n",
    "    'pillar': 'pillar',\n",
    "    'table': 'table',\n",
    "    'person': 'person',\n",
    "    'man': 'person',\n",
    "    'building': 'building',\n",
    "    'city street': 'road',\n",
    "    'curb': 'curb',\n",
    "    'pavement': 'sidewalk',\n",
    "    'road': 'road',\n",
    "    'car': 'car',\n",
    "    'snow': 'snow',\n",
    "    'doorway': 'sloped driveway',\n",
    "    'elevator': 'elevator',\n",
    "    'rail': 'train tracks',\n",
    "    'stair': 'stairs',\n",
    "    'cane': 'white cane',\n",
    "    'door': 'flush door',\n",
    "    'fence': 'fence',\n",
    "    'barrier': 'barrier post',\n",
    "    'bench': 'bench',\n",
    "    'sign': 'sign',\n",
    "    'bin': 'trash bins',\n",
    "    'pole': 'pole',\n",
    "    'street vendor': 'street vendor',\n",
    "    'blind': 'person with a disability',\n",
    "    'dog': 'dog',\n",
    "    'escalator': 'escalator',\n",
    "    'street sign': 'sign post',\n",
    "    'bus stop': 'bus stop',\n",
    "    'railway station': 'train platform',\n",
    "    'tree': 'tree',\n",
    "    'traffic light': 'traffic signals',\n",
    "    'tree trunk': 'tree',\n",
    "    'recycling bin': 'trash bins',\n",
    "    'train track': 'train tracks',\n",
    "    'pedestrian': 'person',\n",
    "    'bus': 'bus',\n",
    "    'city bus': 'bus',\n",
    "    'tour bus': 'bus',\n",
    "    'wall': 'wall',\n",
    "    'elevator door': 'elevator',\n",
    "    'bicycle': 'bicycle',\n",
    "    'crosswalk': 'crosswalk',\n",
    "    'decker bus': 'bus',\n",
    "    'motorcycle': 'motorcycle',\n",
    "    'motorcyclist': 'person',\n",
    "    'biker': 'person',\n",
    "    'motorbike': 'motorcycle',\n",
    "    'warning sign': 'sign',\n",
    "    'hydrant': 'fire hydrant',\n",
    "    'school bus': 'bus',\n",
    "    'vegetation': 'vegetation',\n",
    "    'fountain': 'fountain'\n",
    "}\n",
    "\n",
    "ram_com_obj = list(set(list(ram_obj_map.values())))\n",
    "all_com = natsorted(list(set(ram_com_obj) & set(coco_common_obj) & set(pfb_common_obj)))\n",
    "print(len(all_com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2acf0333-2302-45a6-9146-fe84f0436196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dir = gt_fol # \"/Users/imrankabir/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/GT_N\"\n",
    "\n",
    "gts = natsorted(os.listdir(gt_dir))\n",
    "\n",
    "# skip_list = [\n",
    "#     \"video-10-segment-1.csv\", \"video-9-segment-2.csv\"\n",
    "# ]\n",
    "skip_list = []\n",
    "\n",
    "gts = [x.split('.')[0] for x in gts if x.endswith('.csv') and int(x.split('-')[1])<=16 and x not in skip_list]#[:1]\n",
    "\n",
    "# gts = ['video-1-segment-4']\n",
    "\n",
    "len(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546131cf-87ff-4ab9-b9c4-daa894c20ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/GT_N\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/BLIP\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/GPV-1\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/RAM\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/yolo_v7\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/HRNet_V2\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/mask_rcnn\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/faster_rcnn\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/Random\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/ALL_1\n",
      "/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/ALL_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    'GT_N', 'BLIP', 'GPV-1', 'RAM', 'yolo_v7', 'HRNet_V2', 'mask_rcnn', 'faster_rcnn', 'Random', 'ALL_1', 'ALL_0'\n",
    "]\n",
    "\n",
    "models_f1 = {}\n",
    "\n",
    "for model in models:\n",
    "    print(os.path.join(data_path, model))\n",
    "\n",
    "    p_, r_, f1_, pn_s_ = calculate_model_ap_ar_af1(\n",
    "        gt_fol, [f'{gt}.csv' for gt in gts], os.path.join(data_path, model), \n",
    "        obj_list=all_com\n",
    "    )\n",
    "    models_f1[model] = f1_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f132ab5e-a2fc-41cd-be50-00787822a69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GT_N': 1.0,\n",
       " 'BLIP': 0.8222433460076046,\n",
       " 'GPV-1': 0.7855787476280834,\n",
       " 'RAM': 0.6573519627411842,\n",
       " 'yolo_v7': 0.8183381088825215,\n",
       " 'HRNet_V2': 0.7285877426722497,\n",
       " 'mask_rcnn': 0.7205623901581723,\n",
       " 'faster_rcnn': 0.7296703296703296,\n",
       " 'Random': 0.3337837837837838,\n",
       " 'ALL_1': 0.41357896915752435,\n",
       " 'ALL_0': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a194f2-9d32-4d07-986b-759a5a1e6db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_sim_dict = {}\n",
    "\n",
    "# for gt in gts:\n",
    "#     v_ = int(gt.split('-')[1])\n",
    "#     s_ = int(gt.split('-')[3])\n",
    "#     sims = get_sim_score(images_dir, v_, s_)\n",
    "#     all_sim_dict[gt] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe69c7ba-e71f-4ae8-968d-0b08bdbc7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('all_sims.pickle', 'wb') as handle:\n",
    "#     pickle.dump(all_sim_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936428f9-40e2-45dc-9ec3-3c5c2b4d3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(mat, alpha):\n",
    "    N_t_s = mat.sum(axis=1)\n",
    "    d_ps = N_t_s.shape[0]\n",
    "    \n",
    "    for ind, row in enumerate(mat):\n",
    "        # new_row = (row + alpha) * (N_t_s[ind] / (N_t_s[ind] + (alpha * d_ps)))\n",
    "        # new_row = new_row / (np.sum(new_row) + 1e-20)\n",
    "        new_row = (row + alpha) / (N_t_s[ind] + (alpha * d_ps))\n",
    "        mat[ind] = new_row\n",
    "\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "357d6755-3ff8-4fc8-8747-7f4ea890318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_matrix(pred_file, objs):\n",
    "    pred_df = pd.read_csv(pred_file)\n",
    "    if limit_frame_count > 0:\n",
    "        if len(list(pred_df.columns)) > limit_frame_count:\n",
    "            pred_df = pred_df.iloc[: , :limit_frame_count]\n",
    "    pred_df = pred_df.transpose()\n",
    "    pred_df.columns = pred_df.iloc[0]\n",
    "    pred_df = pred_df.iloc[1:]\n",
    "    pred_df.columns = map(str.lower, pred_df.columns)\n",
    "    if objs is not None:\n",
    "        pred_df = pred_df.reindex(columns=objs)\n",
    "\n",
    "    pred_df = pred_df.fillna('0').transpose()\n",
    "    \n",
    "    pred = np.array(pred_df).T\n",
    "            \n",
    "    unq_st_str = []\n",
    "    n_o_f = 2**(len(objs))\n",
    "    \n",
    "    for x in range(n_o_f):\n",
    "        str_bit = str(bin(x)).replace('0b', '').zfill(len(objs))\n",
    "        unq_st_str.append(str_bit)\n",
    "\n",
    "    transition_matrix_dict = {\n",
    "        'st': [x for x in unq_st_str]\n",
    "    }\n",
    "    for u_s_s in unq_st_str:\n",
    "        transition_matrix_dict[u_s_s] = [0.0 for _ in unq_st_str]\n",
    "\n",
    "    transition_matrix = pd.DataFrame(transition_matrix_dict)\n",
    "    transition_matrix = transition_matrix.set_index('st')\n",
    "\n",
    "    act_st = []\n",
    "\n",
    "    for f in range(1, pred.shape[0]):\n",
    "        s_prev = ''.join([str(ch) for ch in pred[f-1]])\n",
    "        s_now = ''.join([str(ch) for ch in pred[f]])\n",
    "        transition_matrix[s_now][s_prev] += 1.0\n",
    "        if f == 1:\n",
    "            act_st.append(int(s_prev, 2))\n",
    "            act_st.append(int(s_now, 2))\n",
    "        else:\n",
    "            act_st.append(int(s_now, 2))\n",
    "\n",
    "    transition_matrix = np.array(transition_matrix)\n",
    "\n",
    "    transition_matrix = laplace_smoothing(transition_matrix, alpha=1e-2)  # max([np.max(transition_matrix)/5])\n",
    "\n",
    "    for tr_ind, tm_row in enumerate(transition_matrix):\n",
    "        if tm_row.sum() == 0.0:\n",
    "            transition_matrix[tr_ind] = tm_row + 1/tm_row.shape[0]\n",
    "            \n",
    "    return transition_matrix, act_st\n",
    "\n",
    "\n",
    "def get_transition_matrix_from_arr(pred):\n",
    "    unq_st_str = []\n",
    "    n_o_f = 2**(pred.shape[1])\n",
    "    \n",
    "    for x in range(n_o_f):\n",
    "        str_bit = str(bin(x)).replace('0b', '').zfill(pred.shape[1])\n",
    "        unq_st_str.append(str_bit)\n",
    "\n",
    "    transition_matrix_dict = {\n",
    "        'st': [x for x in unq_st_str]\n",
    "    }\n",
    "    for u_s_s in unq_st_str:\n",
    "        transition_matrix_dict[u_s_s] = [0.0 for _ in unq_st_str]\n",
    "\n",
    "    transition_matrix = pd.DataFrame(transition_matrix_dict)\n",
    "    transition_matrix = transition_matrix.set_index('st')\n",
    "\n",
    "    for f in range(1, pred.shape[0]):\n",
    "        s_prev = ''.join([str(ch) for ch in pred[f-1]])\n",
    "        s_now = ''.join([str(ch) for ch in pred[f]])\n",
    "        transition_matrix[s_now][s_prev] += 1.0\n",
    "\n",
    "    transition_matrix = np.array(transition_matrix)\n",
    "\n",
    "    transition_matrix = laplace_smoothing(transition_matrix, alpha=1e-2)  # max([np.max(transition_matrix)/5])\n",
    "\n",
    "    for tr_ind, tm_row in enumerate(transition_matrix):\n",
    "        if tm_row.sum() == 0.0:\n",
    "            transition_matrix[tr_ind] = tm_row + 1/tm_row.shape[0]\n",
    "            \n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a644822-7e68-466a-b8aa-f8d4fe093564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_st_p_from_t_mat(transition_matrix):\n",
    "    I = np.identity(transition_matrix.shape[0])\n",
    "    P_I = transition_matrix - I\n",
    "    co_eff = P_I.T\n",
    "\n",
    "    const = np.array([0.0 for _ in range(co_eff.shape[0])])\n",
    "    co_eff =  np.append(np.ones((1, co_eff.shape[1])), co_eff, axis=0)\n",
    "    const = np.append(np.array([1]), const)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        p_s_ifs = lsqr(co_eff, const)[0] # np.linalg.solve(co_eff, const)\n",
    "    except:\n",
    "        print(det(co_eff), vid_n, seg_n)\n",
    "        p_s_ifs = lsqr(co_eff, const)[0] # np.linalg.solve(co_eff, const)\n",
    "\n",
    "    p_s_ifs = list(p_s_ifs)\n",
    "    # print(p_s_ifs)\n",
    "    # for s_ind in range((2**(unq_st[0].shape[0]))-len(p_s_ifs)):\n",
    "    #     p_s_ifs.append(0.0)\n",
    "\n",
    "    # p_s_ifs = np.array(p_s_ifs)\n",
    "\n",
    "    return p_s_ifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17d0447-de6b-4990-9fcc-705ac018ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(ss_probs):\n",
    "    if len(ss_probs) <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    tot_ss_ent = 0\n",
    "\n",
    "    for prb in ss_probs:\n",
    "        if prb == 0:\n",
    "            log_p_ss = 0\n",
    "        else:\n",
    "            try:\n",
    "                log_p_ss = math.log2(prb)\n",
    "            except:\n",
    "                log_p_ss = 0.0 # math.log2(prb+1e-15)\n",
    "\n",
    "        t_ent = - prb * log_p_ss\n",
    "\n",
    "        tot_ss_ent = tot_ss_ent + t_ent\n",
    "\n",
    "    tot_ss_ent = tot_ss_ent / math.log2(len(ss_probs))\n",
    "\n",
    "    return tot_ss_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bbbc39b-2fc3-4e28-b954-752501838376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_matrix(gt_file, objs):\n",
    "    gt_df = pd.read_csv(gt_file)\n",
    "    if limit_frame_count > 0:\n",
    "        if len(list(gt_df.columns)) > limit_frame_count:\n",
    "            gt_df = gt_df.iloc[: , :limit_frame_count]\n",
    "    gt_df = gt_df.transpose()\n",
    "    gt_df.columns = gt_df.iloc[0]\n",
    "    gt_df = gt_df.iloc[1:]\n",
    "    gt_df.columns = map(str.lower, gt_df.columns)\n",
    "    if objs is not None:\n",
    "        gt_df = gt_df.reindex(columns=objs)\n",
    "\n",
    "    gt_df = gt_df.fillna('0').transpose()\n",
    "\n",
    "    all_states = []\n",
    "    n_o_s = 2**(len(objs))\n",
    "\n",
    "    for x in range(n_o_s):\n",
    "        str_bit = str(bin(x)).replace('0b', '').zfill(len(objs))\n",
    "        all_states.append(str_bit)\n",
    "\n",
    "    emission_matrix_dict = {\n",
    "        'st': [x for x in all_states]\n",
    "    }\n",
    "    for u_f, _ in enumerate(range(len(list(gt_df.columns))+1)):\n",
    "        emission_matrix_dict[str(u_f)] = [0.0 for _ in all_states]\n",
    "\n",
    "    emission_matrix = pd.DataFrame(emission_matrix_dict)\n",
    "    emission_matrix = emission_matrix.set_index('st') \n",
    "\n",
    "    frame_state_dict = {}\n",
    "    for col in gt_df.columns:\n",
    "        frm_df = gt_df.reindex(columns=[col])\n",
    "        c_state = \"\".join([str(x) for x in np.array(frm_df)[:, 0]])\n",
    "        c_f = col.replace('_', '-').split('-')[-1]\n",
    "        if c_state not in frame_state_dict.keys():\n",
    "            frame_state_dict[c_state] = []\n",
    "        frame_state_dict[c_state].append(c_f)\n",
    "\n",
    "    for f_st in all_states:\n",
    "        if f_st not in frame_state_dict.keys():\n",
    "            oth_prob = 0.1\n",
    "            prob_each = oth_prob / len(list(gt_df.columns))\n",
    "            emission_matrix[str(len(list(gt_df.columns)))][f_st] = 1.0 - oth_prob\n",
    "            for f_f, _ in enumerate(gt_df.columns):\n",
    "                emission_matrix[str(f_f)][f_st] = prob_each\n",
    "        else:\n",
    "            prob_each = 1 / len(frame_state_dict[f_st])\n",
    "            for f_f in frame_state_dict[f_st]:\n",
    "                emission_matrix[f_f][f_st] = prob_each\n",
    "\n",
    "    emission_matrix = np.array(emission_matrix)\n",
    "\n",
    "    emission_matrix = laplace_smoothing(emission_matrix, alpha=1e-3)\n",
    "\n",
    "    return emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "120032cb-979a-409b-9804-9d13dd25ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inital_prob_dist_and_obsrv_seq(pred_file, objs):\n",
    "    pred_df = pd.read_csv(pred_file)\n",
    "    if limit_frame_count > 0:\n",
    "        if len(list(pred_df.columns)) > limit_frame_count:\n",
    "            pred_df = pred_df.iloc[: , :limit_frame_count]\n",
    "    pred_df = pred_df.transpose()\n",
    "    pred_df.columns = pred_df.iloc[0]\n",
    "    pred_df = pred_df.iloc[1:]\n",
    "    pred_df.columns = map(str.lower, pred_df.columns)\n",
    "    if objs is not None:\n",
    "        pred_df = pred_df.reindex(columns=objs)\n",
    "\n",
    "    pred_df = pred_df.fillna('0').transpose()\n",
    "    \n",
    "    pred = np.array(pred_df).T\n",
    "            \n",
    "    unq_st_str = []\n",
    "    n_o_f = 2**(len(objs))\n",
    "    \n",
    "    for x in range(n_o_f):\n",
    "        str_bit = str(bin(x)).replace('0b', '').zfill(len(objs))\n",
    "        unq_st_str.append(str_bit)\n",
    "\n",
    "    init_matrix_dict = {\n",
    "        'st': ['init']\n",
    "    }\n",
    "    \n",
    "    for u_s_s in unq_st_str:\n",
    "        init_matrix_dict[u_s_s] = [0.0]\n",
    "\n",
    "    init_matrix = pd.DataFrame(init_matrix_dict)\n",
    "    init_matrix = init_matrix.set_index('st')\n",
    "\n",
    "    \n",
    "    s_init = ''.join([str(ch) for ch in pred[0]])\n",
    "    init_matrix[s_init]['init'] += 1.0\n",
    "\n",
    "    init_matrix = np.array(init_matrix)\n",
    "\n",
    "    init_matrix = laplace_smoothing(init_matrix, alpha=1e-4)  # max([np.max(init_matrix)/5, 1e-5])\n",
    "\n",
    "    for tr_ind, tm_row in enumerate(init_matrix):\n",
    "        if tm_row.sum() == 0.0:\n",
    "            init_matrix[tr_ind] = tm_row + 1/tm_row.shape[0]\n",
    "\n",
    "    obsrv_seq = np.array([f for f in range(0, pred.shape[0])])        \n",
    "            \n",
    "    return init_matrix, obsrv_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "150b1873-4be4-4fc4-bebb-701b3e400d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(y, A, B, pi):\n",
    "    \"\"\"\n",
    "        viterbi algorithm\n",
    "        :param y: observation sequence\n",
    "        :param A: the transition matrix\n",
    "        :param B: the emission matrix\n",
    "        :param pi: the initial probability distribution\n",
    "    \"\"\"\n",
    "    A = -np.log(A)\n",
    "    B = -np.log(B)\n",
    "    pi = -np.log(pi)\n",
    "    \n",
    "    N = B.shape[0]\n",
    "    x_seq = np.zeros([N, 0])\n",
    "    V = B[:, y[0]] + pi\n",
    "\n",
    "    # forward to compute the optimal value function V\n",
    "    for y_ in y[1:]:\n",
    "        _V = np.tile(B[:, y_], reps=[N, 1]).T + A.T + np.tile(V, reps=[N, 1])\n",
    "        x_ind = np.argmin(_V, axis=1)\n",
    "        x_seq = np.hstack([x_seq, np.c_[x_ind]])\n",
    "        V = _V[np.arange(N), x_ind]\n",
    "\n",
    "    x_T = np.argmin(V)\n",
    "    max_P = V[x_T]\n",
    "\n",
    "    # backward to fetch optimal sequence\n",
    "    x_seq_opt, i = np.zeros(x_seq.shape[1]+1), x_seq.shape[1]\n",
    "    prev_ind = x_T\n",
    "\n",
    "    while i >= 0:\n",
    "        x_seq_opt[i] = prev_ind\n",
    "        i -= 1\n",
    "        prev_ind = x_seq[int(prev_ind), i]\n",
    "    return x_seq_opt, max_P\n",
    "\n",
    "def viterbi_bk(y, A, B, pi):\n",
    "    \"\"\"\n",
    "        viterbi algorithm\n",
    "        :param y: observation sequence\n",
    "        :param A: the transition matrix\n",
    "        :param B: the emission matrix\n",
    "        :param pi: the initial probability distribution\n",
    "    \"\"\"\n",
    "    # A = np.log10(A)\n",
    "    # B = np.log10(B)\n",
    "    # pi = np.log10(pi)\n",
    "    \n",
    "    N = B.shape[0]\n",
    "    x_seq = np.zeros([N, 0])\n",
    "    V = B[:, y[0]] * pi\n",
    "\n",
    "    # forward to compute the optimal value function V\n",
    "    for y_ in y[1:]:\n",
    "        _V = np.tile(B[:, y_], reps=[N, 1]).T * A.T * np.tile(V, reps=[N, 1])\n",
    "        x_ind = np.argmax(_V, axis=1)\n",
    "        x_seq = np.hstack([x_seq, np.c_[x_ind]])\n",
    "        V = _V[np.arange(N), x_ind]\n",
    "\n",
    "    x_T = np.argmax(V)\n",
    "    max_P = V[x_T]\n",
    "\n",
    "    # backward to fetch optimal sequence\n",
    "    x_seq_opt, i = np.zeros(x_seq.shape[1]+1), x_seq.shape[1]\n",
    "    prev_ind = x_T\n",
    "\n",
    "    while i >= 0:\n",
    "        x_seq_opt[i] = prev_ind\n",
    "        i -= 1\n",
    "        prev_ind = x_seq[int(prev_ind), i]\n",
    "    return x_seq_opt, max_P\n",
    "\n",
    "\n",
    "def viterbi_2(y, A, B, pi, x):\n",
    "    \"\"\"\n",
    "        viterbi algorithm\n",
    "        :param y: observation sequence\n",
    "        :param A: the transition matrix\n",
    "        :param B: the emission matrix\n",
    "        :param pi: the initial probability distribution\n",
    "        :param x: model heat map sequence \n",
    "    \"\"\"\n",
    "    current_prob = pi[0, x[0]] * B[x[0]][0]\n",
    "\n",
    "    for j, x_ in enumerate(x[1:]):\n",
    "        # print(A[x[j]][x_], B[x_][j+1], x_, j+1)\n",
    "        current_prob = current_prob * A[x[j]][x_] * B[x_][j+1]\n",
    "        \n",
    "    return x, -np.log(current_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a107fc46-60f9-4c14-878d-b4ec28ffd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_dist(s1, s2):\n",
    "    assert len(s1) == len(s2)\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "\n",
    "def calc_path_dist(pth1, pth2):\n",
    "    tot_h_dist = 0\n",
    "    all_p_dists__ = []\n",
    "    for p_c, p_ in enumerate(pth1):\n",
    "        h_dist = hamming_dist(p_, pth2[p_c]) / len(p_)\n",
    "        all_p_dists__.append(h_dist)\n",
    "        tot_h_dist = tot_h_dist + h_dist\n",
    "    dist_pth_ = tot_h_dist / len(pth1)\n",
    "    return dist_pth_, np.array(all_p_dists__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e00e272c-87e9-476d-85ca-6605fb4f94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApEn(U, m, r):\n",
    "    def _maxdist(x_i, x_j):\n",
    "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "    \n",
    "    def _phi(m):\n",
    "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "        C = [\n",
    "            len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0)\n",
    "            for x_i in x\n",
    "        ]\n",
    "        return (N - m + 1.0) ** (-1) * sum(np.log(C))\n",
    "    \n",
    "    N = len(U)\n",
    "    \n",
    "    return abs(_phi(m + 1) - _phi(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3c2e8b9-1413-497c-9527-0c528dd07b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_heat_map_from_arr(gt_data, pred_data, obj_list=None, d_s=[]):\n",
    "    hm_ = (gt_data*2) - pred_data\n",
    "\n",
    "    color_tp = 'rgb(71, 137, 209)' \n",
    "    color_tn = 'rgb(104, 212, 202)'\n",
    "    color_fp = 'rgb(202, 121, 59)' \n",
    "    color_fn = 'rgb(198, 59, 59)'\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    colorscale = [\n",
    "        [0, color_fp],\n",
    "        [0.33333, color_tn],\n",
    "        [0.66667, color_tp],\n",
    "        [1, color_fn]\n",
    "    ]\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template=\"simple_white\",\n",
    "        xaxis=dict(title_text=\"Frames\", tickmode='linear'),\n",
    "        yaxis=dict(title_text=\"Objects\",  tickmode='linear'),\n",
    "        width=1000,\n",
    "        height=250,\n",
    "        margin=dict(l=0, r=0, t=10, b=5),\n",
    "        title=dict(\n",
    "            text=\"\",\n",
    "            font=dict(size=16, color=\"black\"),\n",
    "            x=0.5,\n",
    "            y=0.995\n",
    "    \n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hm_,\n",
    "            x=[f'{i} {d_s[i]:.2f}' for i in range(hm_.shape[1])],\n",
    "            y=[y.capitalize() for i, y in enumerate(obj_list)],\n",
    "            colorscale=colorscale,\n",
    "            zmin=-1,\n",
    "            zmax=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    # fig.add_traces(go.Bar(x=[], y =[], name='TP',\n",
    "    #                  marker_color=color_tp))\n",
    "    # fig.add_traces(go.Bar(x=[], y =[], name='FP',\n",
    "    #                  marker_color=color_fp))\n",
    "    # fig.add_traces(go.Bar(x=[], y =[], name='TN',\n",
    "    #                  marker_color=color_tn))\n",
    "    # fig.add_traces(go.Bar(x=[], y =[], name='FN',\n",
    "    #                  marker_color=color_fn))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Courier New, monospace\",\n",
    "        font_color=\"black\",\n",
    "        title_font_family=\"Courier New, monospace\",\n",
    "        title_font_color=\"black\",\n",
    "        legend_title_font_color=\"black\",\n",
    "        font=dict(size=14),\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "      colorbar_tickmode='array',\n",
    "      colorbar_ticktext=['FP', 'TN', 'TP', 'FN'],\n",
    "      colorbar_tickvals=[-1, 0, 1, 2],\n",
    "      colorbar_tickangle=0,\n",
    "      selector=dict(type='heatmap')\n",
    "     )\n",
    "\n",
    "    fig.update_xaxes(ticklabelposition='outside')\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        tickson=\"boundaries\",\n",
    "        ticklen=5,\n",
    "        tickangle=90\n",
    "    )\n",
    "    fig.update_layout(\n",
    "         xaxis=dict(showgrid=True),\n",
    "         yaxis=dict(showgrid=True)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(xaxis=dict(domain=[0, 1]))\n",
    "    \n",
    "    hm_figs = fig\n",
    "\n",
    "    return hm_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f437190c-6cec-4e8b-9ff5-605747379acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_heat_map_model_only_from_arr(pred_data, obj_list=None, d_s=[]):\n",
    "    hm_ = pred_data # gt_data.mul(2).add(pred_data.mul(-1), fill_value=0)\n",
    "\n",
    "    color_tp = 'rgb(71, 137, 209)' \n",
    "    color_tn = 'rgb(104, 212, 202)'\n",
    "    color_fp = 'rgb(202, 121, 59)' \n",
    "    color_fn = 'rgb(198, 59, 59)'\n",
    "    color_agreement = 'rgb(6, 200, 115)' # green\n",
    "    color_disagreement = 'rgb(211, 6, 50)'\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    colorscale = [\n",
    "        [0, color_disagreement],\n",
    "        [1, color_agreement]\n",
    "    ]\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template=\"simple_white\",\n",
    "        xaxis=dict(title_text=\"Frames\", tickmode='linear'),\n",
    "        yaxis=dict(title_text=\"Objects\",  tickmode='linear'),\n",
    "        width=1000,\n",
    "        height=250,\n",
    "        margin=dict(l=0, r=0, t=10, b=5),\n",
    "        title=dict(\n",
    "            text=\"\",\n",
    "            font=dict(size=16, color=\"black\"),\n",
    "            x=0.5,\n",
    "            y=0.995\n",
    "    \n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hm_,\n",
    "            x=[f'{i} {d_s[i]:.2f}' for i in range(hm_.shape[1])],\n",
    "            y=[y.capitalize() for i, y in enumerate(obj_list)],\n",
    "            colorscale=colorscale,\n",
    "            zmin=0,\n",
    "            zmax=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # fig.add_traces(go.Bar(x=[], y =[], name='TP',\n",
    "    #                  marker_color=color_tp))\n",
    "    # fig.add_traces(go.Bar(x=[], y =[], name='FP',\n",
    "    #                  marker_color=color_fp))\n",
    "    # fig.add_traces(go.Bar(x=[], y =[], name='TN',\n",
    "    #                  marker_color=color_tn))\n",
    "    # fig.add_traces(go.Bar(x=[], y =[], name='FN',\n",
    "    #                  marker_color=color_fn))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Courier New, monospace\",\n",
    "        font_color=\"black\",\n",
    "        title_font_family=\"Courier New, monospace\",\n",
    "        title_font_color=\"black\",\n",
    "        legend_title_font_color=\"black\",\n",
    "        font=dict(size=14),\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "      colorbar_tickmode='array',\n",
    "      colorbar_ticktext=['Disagree', 'Agree'],\n",
    "      colorbar_tickvals=[0, 1],\n",
    "      colorbar_tickangle=0,\n",
    "      selector=dict(type='heatmap')\n",
    "     )\n",
    "\n",
    "    fig.update_xaxes(ticklabelposition='outside')\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        tickson=\"boundaries\",\n",
    "        ticklen=5,\n",
    "        tickangle=90\n",
    "    )\n",
    "    fig.update_layout(\n",
    "         xaxis=dict(showgrid=True),\n",
    "         yaxis=dict(showgrid=True)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(xaxis=dict(domain=[0, 1]))\n",
    "    \n",
    "    hm_figs = fig\n",
    "\n",
    "    return hm_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a095237-25e1-4ca4-918f-a5cd32c7fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vetical_axis_lines(x_labels, cg):\n",
    "\n",
    "    vertical_lines = []\n",
    "\n",
    "    for i in range(len(x_labels)):\n",
    "        vertical_lines.append({\n",
    "            'type': 'line',\n",
    "            'x0': i / len(x_labels),\n",
    "            'x1': i / len(x_labels),\n",
    "            'y0': 0,\n",
    "            'y1': 1,\n",
    "            'xref': 'paper',  \n",
    "            'yref': 'paper',  \n",
    "            'line': {\n",
    "                'color': cg, \n",
    "                'width': 2,  \n",
    "            },\n",
    "            'opacity': 0.5\n",
    "    })\n",
    "        \n",
    "    return vertical_lines\n",
    "\n",
    "\n",
    "def get_horizontal_axis_lines(y_labels, cg):\n",
    "\n",
    "    horizontal_lines = []\n",
    "\n",
    "    for i in range(len(y_labels) + 1):\n",
    "        horizontal_lines.append({\n",
    "            'type': 'line',\n",
    "            'x0': 0,\n",
    "            'x1': 1,\n",
    "            'y0': i / len(y_labels),\n",
    "            'y1': i / len(y_labels),\n",
    "            'xref': 'paper',\n",
    "            'yref': 'paper', \n",
    "            'line': {\n",
    "                'color': cg, \n",
    "                'width': 2, \n",
    "            },\n",
    "            'opacity': 0.5\n",
    "        })\n",
    "\n",
    "    return horizontal_lines   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dbee603-7091-4323-a4a0-201231adb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_heat_map_from_arr2(gt_data, pred_data, obj_list=None, d_s=[]):\n",
    "    hm_ = (gt_data*2) - pred_data\n",
    "\n",
    "    color_tp = 'rgb(71, 137, 209)' \n",
    "    color_tn = 'rgb(104, 212, 202)'\n",
    "    color_fp = 'rgb(202, 121, 59)' \n",
    "    color_fn = 'rgb(198, 59, 59)'\n",
    "    color_grid = 'rgb(113,215,206)'\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    colorscale = [\n",
    "        [0, color_fp],\n",
    "        [0.33333, color_tn],\n",
    "        [0.66667, color_tp],\n",
    "        [1, color_fn]\n",
    "    ]\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template=\"simple_white\",\n",
    "        width=920,\n",
    "        height=500,\n",
    "        margin=dict(l=0, r=0, t=10, b=5),\n",
    "        title=dict(\n",
    "            text=\"\",\n",
    "            font=dict(size=32, color=\"black\"),\n",
    "            x=0.5,\n",
    "            y=0.995\n",
    "    \n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=\"Frames\", \n",
    "            tickmode='linear',\n",
    "            showgrid=False, \n",
    "            dtick=1, \n",
    "            gridwidth=1\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=\"Objects\",  \n",
    "            tickmode='linear',\n",
    "            showgrid=False, \n",
    "            dtick=1, \n",
    "            gridwidth=1, \n",
    "        )\n",
    "    )\n",
    "\n",
    "    X = [f'{i}' for i in range(hm_.shape[1])]\n",
    "    Y = [y.capitalize() for i, y in enumerate(obj_list)]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hm_,\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            colorscale=colorscale,\n",
    "            showscale=False,\n",
    "            zmin=-1,\n",
    "            zmax=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        name=\"TP\",\n",
    "        marker=dict(size=60, symbol='square', color=color_tp),\n",
    "        showlegend=True\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        name=\"TN\",\n",
    "        marker=dict(size=60, symbol='square', color=color_tn),\n",
    "        showlegend=True\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        name=\"FP\",\n",
    "        marker=dict(size=60, symbol='square', color=color_fp),\n",
    "        showlegend=True\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        name=\"FN\",\n",
    "        marker=dict(size=60, symbol='square', color=color_fn),\n",
    "        showlegend=True\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Courier New, monospace\",\n",
    "        font_color=\"black\",\n",
    "        title_font_family=\"Courier New, monospace\",\n",
    "        title_font_color=\"black\",\n",
    "        legend_title_font_color=\"black\",\n",
    "        legend=dict(orientation=\"h\", y=1.14, x=0.1),\n",
    "        font=dict(size=28),\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "      colorbar_tickmode='array',\n",
    "      colorbar_ticktext=['FP', 'TN', 'TP', 'FN'],\n",
    "      colorbar_tickvals=[-1, 0, 1, 2],\n",
    "      colorbar_tickangle=0,\n",
    "      selector=dict(type='heatmap')\n",
    "     )\n",
    "\n",
    "    fig.update_xaxes(ticklabelposition='outside')\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        tickson=\"boundaries\",\n",
    "        ticklen=5,\n",
    "        tickangle=90\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(xaxis=dict(domain=[0,1]))\n",
    "    layout_shapes_list = []\n",
    "    layout_shapes_list.extend(get_vetical_axis_lines(X, color_grid))\n",
    "    layout_shapes_list.extend(get_horizontal_axis_lines(Y, color_grid))   \n",
    "\n",
    "    fig.update_layout(shapes = tuple(layout_shapes_list))\n",
    "    \n",
    "    hm_figs = fig\n",
    "\n",
    "    return hm_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff43dd6a-235d-4df9-8d35-ab9ef1135472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_heat_map_model_only_from_arr2(pred_data, obj_list=None, d_s=[]):\n",
    "    hm_ = pred_data # gt_data.mul(2).add(pred_data.mul(-1), fill_value=0)\n",
    "\n",
    "    color_tp = 'rgb(71, 137, 209)' \n",
    "    color_tn = 'rgb(104, 212, 202)'\n",
    "    color_fp = 'rgb(202, 121, 59)' \n",
    "    color_fn = 'rgb(198, 59, 59)'\n",
    "    color_agreement = 'rgb(6, 200, 115)' # green\n",
    "    color_disagreement = 'rgb(211, 6, 50)'\n",
    "    color_grid = 'black'\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    colorscale = [\n",
    "        [0, color_disagreement],\n",
    "        [1, color_agreement]\n",
    "    ]\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template=\"simple_white\",\n",
    "        xaxis=dict(title_text=\"Frames\", tickmode='linear'),\n",
    "        yaxis=dict(title_text=\"Objects\",  tickmode='linear'),\n",
    "        width=920,\n",
    "        height=500,\n",
    "        margin=dict(l=0, r=0, t=10, b=5),\n",
    "        title=dict(\n",
    "            text=\"\",\n",
    "            font=dict(size=32, color=\"black\"),\n",
    "            x=0.5,\n",
    "            y=0.995\n",
    "    \n",
    "        )\n",
    "    )\n",
    "    X=[f'{i}' for i in range(hm_.shape[1])]\n",
    "    Y=[y.capitalize() for i, y in enumerate(obj_list)]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hm_,\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            colorscale=colorscale,\n",
    "            showscale=False,\n",
    "            zmin=0,\n",
    "            zmax=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        name=\"Presence\",\n",
    "        marker=dict(size=60, symbol='square', color=color_agreement),\n",
    "        showlegend=True\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        name=\"Absence\",\n",
    "        marker=dict(size=60, symbol='square', color=color_disagreement),\n",
    "        showlegend=True\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Courier New, monospace\",\n",
    "        font_color=\"black\",\n",
    "        title_font_family=\"Courier New, monospace\",\n",
    "        title_font_color=\"black\",\n",
    "        legend_title_font_color=\"black\",\n",
    "        legend=dict(orientation=\"h\", y=1.14, x=0.1),\n",
    "        font=dict(size=28),\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "      colorbar_tickmode='array',\n",
    "      colorbar_ticktext=['Disagree', 'Agree'],\n",
    "      colorbar_tickvals=[0, 1],\n",
    "      colorbar_tickangle=0,\n",
    "      selector=dict(type='heatmap')\n",
    "     )\n",
    "\n",
    "    fig.update_xaxes(ticklabelposition='outside')\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        tickson=\"boundaries\",\n",
    "        ticklen=5,\n",
    "        tickangle=90\n",
    "    )\n",
    "    # fig.update_layout(\n",
    "    #      xaxis=dict(showgrid=True),\n",
    "    #      yaxis=dict(showgrid=True)\n",
    "    # )\n",
    "    \n",
    "    fig.update_layout(xaxis=dict(domain=[0, 1]))\n",
    "\n",
    "    layout_shapes_list = []\n",
    "    layout_shapes_list.extend(get_vetical_axis_lines(X, color_grid))\n",
    "    layout_shapes_list.extend(get_horizontal_axis_lines(Y, color_grid))   \n",
    "\n",
    "    fig.update_layout(shapes = tuple(layout_shapes_list))\n",
    "    \n",
    "    hm_figs = fig\n",
    "\n",
    "    return hm_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30173f20-127b-4c65-a62d-b2e1ca31d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dum_pred_from_f1(gt_f__, org_f1, pred_ct, obj_list_a):\n",
    "    dd_df = pd.read_csv(gt_f__)\n",
    "    if limit_frame_count > 0:\n",
    "        if len(list(dd_df.columns)) > limit_frame_count:\n",
    "            dd_df = dd_df.iloc[: , :limit_frame_count]\n",
    "\n",
    "    dd_df = dd_df.transpose()\n",
    "    dd_df.columns = [x__.lower() for x__ in dd_df.iloc[0]]\n",
    "    dd_df = dd_df.reindex(columns=obj_list_a).iloc[1:].transpose()\n",
    "    dd_np = np.array(dd_df)\n",
    "    \n",
    "    unique, counts = np.unique(np.array(dd_df), return_counts=True)\n",
    "    total_pred_c = sum(counts)\n",
    "    pred_counts = dict(zip(unique, counts))\n",
    "    fra_rep = [int(x) for x in str(Fraction(org_f1).limit_denominator()).split('/')]\n",
    "    tp_frac = fra_rep[0]/2\n",
    "    fp_plus_fn_frac = fra_rep[1] - fra_rep[0]\n",
    "    dum_pred_dfs = []\n",
    "    for p_tp in range(pred_counts[1], 0, -1):\n",
    "        new_dd_np = np.zeros(dd_np.shape).astype(int)\n",
    "        p_fp_plus_fn = round((fp_plus_fn_frac/tp_frac) * p_tp)\n",
    "        p_fn = pred_counts[1] - p_tp\n",
    "        p_fp = p_fp_plus_fn - p_fn\n",
    "        p_tn = total_pred_c - (p_tp + p_fn + p_fp)\n",
    "        p_f1 = (2 * p_tp)/(p_tp+p_tp+p_fp+p_fn)\n",
    "        p_dev = abs((p_f1 - org_f1)/p_f1)\n",
    "    \n",
    "        if p_tn < 0 or p_dev > 0.08:\n",
    "            continue\n",
    "        \n",
    "        pos_posit = np.argwhere(dd_np==1)\n",
    "        pos_neg = np.argwhere(dd_np==0)\n",
    "        p_rc_samp = random.sample(range(0, pos_posit.shape[0]), p_tp)\n",
    "        \n",
    "        try:\n",
    "            n_rc_samp = random.sample(range(0, pos_neg.shape[0]), p_fp)\n",
    "        except:\n",
    "            print(pos_neg.shape, p_fp)\n",
    "            if p_fp < 0:\n",
    "                p_fp = 0\n",
    "            n_rc_samp = random.sample(range(0, pos_neg.shape[0]), p_fp)\n",
    "            \n",
    "        tp_rrr, tp_ccc = pos_posit[:, 0][p_rc_samp], pos_posit[:, 1][p_rc_samp]\n",
    "        fp_rrr, fp_ccc = pos_neg[:, 0][n_rc_samp], pos_neg[:, 1][n_rc_samp]\n",
    "    \n",
    "        new_dd_np[tp_rrr, tp_ccc] = 1\n",
    "        new_dd_np[fp_rrr, fp_ccc] = 1\n",
    "\n",
    "        new_dd_df = pd.DataFrame(new_dd_np, index=dd_df.index, columns=dd_df.columns).reset_index()\n",
    "        new_dd_df = new_dd_df.rename(columns={\"index\": \"Object\"})\n",
    "\n",
    "        dum_pred_dfs.append(new_dd_df)\n",
    "        if len(dum_pred_dfs) >= pred_ct:\n",
    "            break\n",
    "\n",
    "    return dum_pred_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "027063fe-eab8-44f3-b1ef-8a44e8bb2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dum_pred_random(gt_f__, pred_ct, obj_list_a):\n",
    "    dd_df = pd.read_csv(gt_f__)\n",
    "    if limit_frame_count > 0:\n",
    "        if len(list(dd_df.columns)) > limit_frame_count:\n",
    "            dd_df = dd_df.iloc[: , :limit_frame_count]\n",
    "\n",
    "    dd_df = dd_df.transpose()\n",
    "    dd_df.columns = [x__.lower() for x__ in dd_df.iloc[0]]\n",
    "    dd_df = dd_df.reindex(columns=obj_list_a).iloc[1:].transpose()\n",
    "    dd_np = np.array(dd_df)\n",
    "    \n",
    "    dum_pred_dfs = []\n",
    "    for d_pred_c in range(pred_ct):\n",
    "        new_dd_np = np.zeros(dd_np.shape).astype(int)\n",
    "        for rw in range(new_dd_np.shape[0]):\n",
    "            for cl in range(new_dd_np.shape[1]):\n",
    "                pred_val = random.randint(0, 1)\n",
    "                new_dd_np[rw, cl] = pred_val\n",
    "\n",
    "        new_dd_df = pd.DataFrame(new_dd_np, index=dd_df.index, columns=dd_df.columns).reset_index()\n",
    "        new_dd_df = new_dd_df.rename(columns={\"index\": \"Object\"})\n",
    "\n",
    "        dum_pred_dfs.append(new_dd_df)\n",
    "\n",
    "    return dum_pred_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efd4602c-6638-4561-9980-d1baafea84fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 3/21 [00:00<00:00, 22.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274\n",
      "0.418\n",
      "0.386\n",
      "0.2898\n",
      "0.7065\n",
      "0.4744\n",
      "0.4467\n",
      "0.3213\n",
      "0.6933\n",
      "0.4273\n",
      "0.4216\n",
      "0.318\n",
      "0.6355\n",
      "0.4802\n",
      "0.4307\n",
      "0.3569\n",
      "0.6294\n",
      "0.4757\n",
      "0.4238\n",
      "0.2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 9/21 [00:00<00:00, 21.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7062\n",
      "0.4599\n",
      "0.4618\n",
      "0.2429\n",
      "(921, 2) 929\n",
      "Sample larger than population or is negative video-4-segment-1 GPV-1\n",
      "0.6963\n",
      "0.4214\n",
      "0.3844\n",
      "0.3313\n",
      "0.6323\n",
      "0.3172\n",
      "0.3005\n",
      "0.201\n",
      "0.6832\n",
      "0.3864\n",
      "0.4534\n",
      "0.2133\n",
      "0.6271\n",
      "0.4593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 12/21 [00:00<00:00, 23.08it/s]/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ibk5106/anaconda3/envs/conda_pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3708\n",
      "0.2986\n",
      "0.6809\n",
      "0.4618\n",
      "0.4732\n",
      "0.302\n",
      "0.4381\n",
      "0.2341\n",
      "0.3742\n",
      "0.2141\n",
      "0.0\n",
      "list index out of range video-9-segment-2 GPT4V\n",
      "video-9-segment-2.csv\n",
      "0.0\n",
      "list index out of range video-9-segment-2 LLaVa\n",
      "video-9-segment-2.csv\n",
      "0.0\n",
      "list index out of range video-9-segment-2 BLIP\n",
      "0.0\n",
      "list index out of range video-9-segment-2 GPV-1\n",
      "0.0\n",
      "list index out of range video-10-segment-1 GPT4V\n",
      "video-10-segment-1.csv\n",
      "0.0\n",
      "list index out of range video-10-segment-1 LLaVa\n",
      "video-10-segment-1.csv\n",
      "0.0\n",
      "list index out of range video-10-segment-1 BLIP\n",
      "0.0\n",
      "list index out of range video-10-segment-1 GPV-1\n",
      "0.6725\n",
      "0.6476\n",
      "0.615\n",
      "0.4533\n",
      "0.7597\n",
      "0.6636\n",
      "0.6499\n",
      "0.4859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 25.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7824\n",
      "0.5491\n",
      "0.4903\n",
      "0.382\n",
      "0.6822\n",
      "0.4837\n",
      "0.4266\n",
      "0.3294\n",
      "0.5317\n",
      "0.5203\n",
      "0.4213\n",
      "0.3988\n",
      "0.6239\n",
      "0.6147\n",
      "0.6\n",
      "0.4461\n",
      "0.6573\n",
      "0.6455\n",
      "0.5881\n",
      "0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "random.seed(100)\n",
    "models = [\n",
    "    'GPT4V', 'LLaVa', 'BLIP', 'GPV-1'\n",
    "]\n",
    "\n",
    "workbook = Workbook()\n",
    "worksheet_s = workbook.active\n",
    "worksheet_s.title = \"Normal\"\n",
    "worksheet_cm = workbook.create_sheet(\"CM\", 0)\n",
    "\n",
    "col = 2\n",
    "\n",
    "for gt_ind, gt in enumerate(tqdm(gts)):\n",
    "    gt_f = os.path.join(gt_fol, f'{gt}.csv')\n",
    "\n",
    "    v_ = int(gt.split('-')[1])\n",
    "    s_ = int(gt.split('-')[3])\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            _, _, f1___, _ = calculate_model_ap_ar_af1(\n",
    "                gt_fol, [f'{gt}.csv'], os.path.join(data_path, model), \n",
    "            )\n",
    "        \n",
    "            f1___ = float(f'{f1___:.4f}')\n",
    "        except:\n",
    "            print(model, gt)\n",
    "            _, _, f1___, _ = calculate_model_ap_ar_af1(\n",
    "                gt_fol, [f'{gt}.csv'], os.path.join(data_path, model), \n",
    "                obj_list=object_list\n",
    "            )\n",
    "        \n",
    "            f1___ = float(f'{f1___:.4f}')\n",
    "\n",
    "        print(f1___)\n",
    "\n",
    "        try:\n",
    "            d_df = get_dum_pred_from_f1(gt_f, f1___, 1, object_list)[0]\n",
    "            export_df_path = f'./sim_f1_for_dashboard/{model}@Shadow'\n",
    "            if not os.path.exists(export_df_path):\n",
    "                os.makedirs(export_df_path)\n",
    "                \n",
    "            d_df.to_csv(os.path.join(export_df_path, f'{gt}.csv'), index=False)\n",
    "        except Exception as e:\n",
    "            print(e, gt, model)\n",
    "            export_df_path = f'./sim_f1_for_dashboard/{model}@Shadow'\n",
    "            if not os.path.exists(export_df_path):\n",
    "                os.makedirs(export_df_path)\n",
    "            try:\n",
    "                shutil.copy(os.path.join(data_path, model, f'{gt}.csv'), export_df_path)\n",
    "            except:\n",
    "                print(f'{gt}.csv')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce2a1a5e-0021-4905-ac01-1897bf9afec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/GPT4V/video-1-segment-5.csv')\n",
    "df.isnull().values.any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
