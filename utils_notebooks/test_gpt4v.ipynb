{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de1d82be-39ed-4e60-9299-c91d8de14cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2528cea-963d-4f2c-9150-c1793d50ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\"\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ad33de0-ed45-4dae-a758-515acf1e85bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Are there a Accent Paving, Barrier Post, Barrier Stump, Bench, Bicycle, Bridge, Building, Bus, Bus Stop, Car, Chair, Closed Sidewalk, Counter, Crosswalk, Curb, Dog, Driveway(flat), Elevator, Escalator, Fence, Fire hydrant, Flush Door, Foldout Sign, Fountain, Gate, Guide dog, Gutter, Hose, Lamp Post, Mail box, Maintenance Vehicle, Motorcycle, Parallel Parking Spot, Paratransit vehicle, Pedestrian Crossing, Person, Person with a disability, Pillar, Pole, Puddle, Push button, Railing, Raised Entryway, Retaining Wall, Road, Road Divider, Road Shoulder, Roadside Parking, Sidewalk, Sidewalk pits, Sign, Sign Post, Sloped Driveway, Slopped Curb, Snow, Stairs, Stop sign, Street Vendor, Table, Tactile Paving, Traffic Signals, Train Platform, Train Tracks, Trash bins, Trash on roads, Tree, Turnstile, Uncontrolled Crossing, Uneven Stairs, Unpaved Road, Unpaved Sidewalk, Vegetation, Wall, Water leakage, Water Pipes, Wet surface, Wheelchair, White Cane, Yard Waste present in the image? Answer for all the objects in dictionary format (i.e. {'car': 'yes'}). return only the dictionary without \\n.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_list = [\n",
    "    \"Accent Paving\", \"Barrier Post\", \"Barrier Stump\", \"Bench\", \"Bicycle\", \"Bridge\", \n",
    "    \"Building\", \"Bus\", \"Bus Stop\", \"Car\", \"Chair\", \"Closed Sidewalk\", \"Counter\", \n",
    "    \"Crosswalk\", \"Curb\", \"Dog\", \"Driveway(flat)\", \"Elevator\", \"Escalator\", \"Fence\", \n",
    "    \"Fire hydrant\", \"Flush Door\", \"Foldout Sign\", \"Fountain\", \"Gate\", \"Guide dog\", \n",
    "    \"Gutter\", \"Hose\", \"Lamp Post\", \"Mail box\", \"Maintenance Vehicle\", \"Motorcycle\", \n",
    "    \"Parallel Parking Spot\", \"Paratransit vehicle\", \"Pedestrian Crossing\", \"Person\", \n",
    "    \"Person with a disability\", \"Pillar\", \"Pole\", \"Puddle\", \"Push button\", \"Railing\", \n",
    "    \"Raised Entryway\", \"Retaining Wall\", \"Road\", \"Road Divider\", \"Road Shoulder\", \n",
    "    \"Roadside Parking\", \"Sidewalk\", \"Sidewalk pits\", \"Sign\", \"Sign Post\", \"Sloped Driveway\", \n",
    "    \"Slopped Curb\", \"Snow\", \"Stairs\", \"Stop sign\", \"Street Vendor\", \"Table\", \"Tactile Paving\", \n",
    "    \"Traffic Signals\", \"Train Platform\", \"Train Tracks\", \"Trash bins\", \"Trash on roads\", \"Tree\", \n",
    "    \"Turnstile\", \"Uncontrolled Crossing\", \"Uneven Stairs\", \"Unpaved Road\", \"Unpaved Sidewalk\", \n",
    "    \"Vegetation\", \"Wall\", \"Water leakage\", \"Water Pipes\", \"Wet surface\", \"Wheelchair\", \n",
    "    \"White Cane\", \"Yard Waste\"\n",
    "]\n",
    "\n",
    "obj_str = ', '.join(object_list)\n",
    "\n",
    "que = f\"Are there a {obj_str} present in the image?\" + \" Answer for all the objects in dictionary format (i.e. {'car': 'yes'}). return only the dictionary without \\n.\"\n",
    "que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77458ebd-d83e-4616-a602-1cb20938b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.path.abspath(os.path.join(os.curdir, '../'))\n",
    "images_dir = os.path.join(ROOT, 'Dashboard Data/Images')\n",
    "data_path = os.path.join(ROOT, 'Dashboard Data')\n",
    "gt_fol = os.path.join(data_path, \"GT_N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47365094-21aa-41dc-be84-0000ae95558b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dir = gt_fol\n",
    "\n",
    "gts = natsorted(os.listdir(gt_dir))\n",
    "\n",
    "skip_list = [\n",
    "    \"video-10-segment-1.csv\", \"video-9-segment-2.csv\"\n",
    "]\n",
    "\n",
    "gts = [x.split('.')[0] for x in gts if x.endswith('.csv') and int(x.split('-')[1])<=16 and x not in skip_list]#[:1]\n",
    "\n",
    "len(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fc285aa-a396-470c-ba1f-b689a8d40540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/Images/video-1-segment-4-frame-0.jpeg\"\n",
    "# base64_image = encode_image(image_path)\n",
    "\n",
    "# payload = {\n",
    "#   \"model\": \"gpt-4-vision-preview\",\n",
    "#   \"messages\": [\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": [\n",
    "#         {\n",
    "#           \"type\": \"text\",\n",
    "#           \"text\": que\n",
    "#         },\n",
    "#         {\n",
    "#           \"type\": \"image_url\",\n",
    "#           \"image_url\": {\n",
    "#             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#           }\n",
    "#         }\n",
    "#       ]\n",
    "#     }\n",
    "#   ],\n",
    "#   \"max_tokens\": 600\n",
    "# }\n",
    "\n",
    "# response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "# dict(response.json())['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c46ffb-4bc3-46a3-916f-afaf5c3e3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13d44946-026d-4a84-afbb-36e6994cceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image: video-16-segment-3-frame-10.jpeg\n",
      "got response\n",
      "current image: video-16-segment-3-frame-11.jpeg\n",
      "got response\n"
     ]
    }
   ],
   "source": [
    "for gt_ind, gt in enumerate(gts):\n",
    "    if gt not in result_dict.keys():\n",
    "        result_dict[gt] = {}\n",
    "        \n",
    "    images_tot = len(glob.glob(\n",
    "        os.path.join(\n",
    "            images_dir,\n",
    "            f'{gt}*'\n",
    "        )\n",
    "    ))\n",
    "    for i in range(images_tot):\n",
    "        if f'{i}' in result_dict[gt].keys():\n",
    "            continue\n",
    "        img_name = f'{gt}-frame-{i}.jpeg'\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        base64_image = encode_image(img_path)\n",
    "        payload = {\n",
    "          \"model\": \"gpt-4-vision-preview\",\n",
    "          \"messages\": [\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": [\n",
    "                {\n",
    "                  \"type\": \"text\",\n",
    "                  \"text\": que\n",
    "                },\n",
    "                {\n",
    "                  \"type\": \"image_url\",\n",
    "                  \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ],\n",
    "          \"max_tokens\": 600\n",
    "        }\n",
    "        print(f\"current image: {img_name}\")\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        try:\n",
    "            out = eval(dict(response.json())['choices'][0]['message']['content'])\n",
    "        except Exception as e:\n",
    "            print(response)\n",
    "            out = eval(dict(response.json())['choices'][0]['message']['content'])\n",
    "            \n",
    "        print(f\"got response\")\n",
    "        result_dict[gt][f'{i}'] = out\n",
    "            \n",
    "        time.sleep(5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c1614d9-e3c3-4191-9770-455ac67fd927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['video-16-segment-3'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e24a1992-4df4-401f-91a1-d73fb4e6ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"gpt4v_out.json\", \"w\") as f: \n",
    "    json.dump(result_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e16960-578c-4d80-8c8a-3aacb40a53cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_pytorch] *",
   "language": "python",
   "name": "conda-env-conda_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
