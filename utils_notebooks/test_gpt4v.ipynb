{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1d82be-39ed-4e60-9299-c91d8de14cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T19:01:44.188736Z",
     "start_time": "2024-03-31T19:01:43.241214Z"
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2528cea-963d-4f2c-9150-c1793d50ef75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T19:01:44.191725Z",
     "start_time": "2024-03-31T19:01:44.189513Z"
    }
   },
   "outputs": [],
   "source": [
    "api_key = \"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\"\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad33de0-ed45-4dae-a758-515acf1e85bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T20:10:46.046276Z",
     "start_time": "2024-03-31T20:10:46.039784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"Are there objects from the following list present in the image? Provide answers for all the objects in dictionary (without any newline(\\\\n)) format (i.e., {'car': 'yes'}). The object list includes: Accent Paving, Barrier Post, Barrier Stump, Bench, Bicycle, Bridge, Building, Bus, Bus Stop, Car, Chair, Closed Sidewalk, Counter, Crosswalk, Curb, Dog, Driveway(flat), Elevator, Escalator, Fence, Fire hydrant, Flush Door, Foldout Sign, Fountain, Gate, Guide dog, Gutter, Hose, Lamp Post, Mail box, Maintenance Vehicle, Motorcycle, Parallel Parking Spot, Paratransit vehicle, Pedestrian Crossing, Person, Person with a disability, Pillar, Pole, Puddle, Push button, Railing, Raised Entryway, Retaining Wall, Road, Road Divider, Road Shoulder, Roadside Parking, Sidewalk, Sidewalk pits, Sign, Sign Post, Sloped Driveway, Slopped Curb, Snow, Stairs, Stop sign, Street Vendor, Table, Tactile Paving, Traffic Signals, Train Platform, Train Tracks, Trash bins, Trash on roads, Tree, Turnstile, Uncontrolled Crossing, Uneven Stairs, Unpaved Road, Unpaved Sidewalk, Vegetation, Wall, Water leakage, Water Pipes, Wet surface, Wheelchair, White Cane, Yard Waste\""
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_list = [\n",
    "    \"Accent Paving\", \"Barrier Post\", \"Barrier Stump\", \"Bench\", \"Bicycle\", \"Bridge\", \n",
    "    \"Building\", \"Bus\", \"Bus Stop\", \"Car\", \"Chair\", \"Closed Sidewalk\", \"Counter\", \n",
    "    \"Crosswalk\", \"Curb\", \"Dog\", \"Driveway(flat)\", \"Elevator\", \"Escalator\", \"Fence\", \n",
    "    \"Fire hydrant\", \"Flush Door\", \"Foldout Sign\", \"Fountain\", \"Gate\", \"Guide dog\", \n",
    "    \"Gutter\", \"Hose\", \"Lamp Post\", \"Mail box\", \"Maintenance Vehicle\", \"Motorcycle\", \n",
    "    \"Parallel Parking Spot\", \"Paratransit vehicle\", \"Pedestrian Crossing\", \"Person\", \n",
    "    \"Person with a disability\", \"Pillar\", \"Pole\", \"Puddle\", \"Push button\", \"Railing\", \n",
    "    \"Raised Entryway\", \"Retaining Wall\", \"Road\", \"Road Divider\", \"Road Shoulder\", \n",
    "    \"Roadside Parking\", \"Sidewalk\", \"Sidewalk pits\", \"Sign\", \"Sign Post\", \"Sloped Driveway\", \n",
    "    \"Slopped Curb\", \"Snow\", \"Stairs\", \"Stop sign\", \"Street Vendor\", \"Table\", \"Tactile Paving\", \n",
    "    \"Traffic Signals\", \"Train Platform\", \"Train Tracks\", \"Trash bins\", \"Trash on roads\", \"Tree\", \n",
    "    \"Turnstile\", \"Uncontrolled Crossing\", \"Uneven Stairs\", \"Unpaved Road\", \"Unpaved Sidewalk\", \n",
    "    \"Vegetation\", \"Wall\", \"Water leakage\", \"Water Pipes\", \"Wet surface\", \"Wheelchair\", \n",
    "    \"White Cane\", \"Yard Waste\"\n",
    "]\n",
    "\n",
    "obj_str = ', '.join(object_list)\n",
    "\n",
    "# que = f\"Are there a {obj_str} present in the image?\" + \" Answer for all the objects in dictionary format (i.e. {'car': 'yes'}). return only the dictionary without \\n.\"\n",
    "que = \"Are there objects from the following list present in the image? Provide answers for all the objects in dictionary (without any newline(\\\\n)) format (i.e., {'car': 'yes'}). The object list includes: \" + f\"{obj_str}\"\n",
    "que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77458ebd-d83e-4616-a602-1cb20938b0da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T19:01:50.176726Z",
     "start_time": "2024-03-31T19:01:50.174168Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = os.path.abspath(os.path.join(os.curdir, '../'))\n",
    "images_dir = os.path.join(ROOT, 'Dashboard Data/Images')\n",
    "data_path = os.path.join(ROOT, 'Dashboard Data')\n",
    "gt_fol = os.path.join(data_path, \"GT_N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47365094-21aa-41dc-be84-0000ae95558b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T19:01:51.969765Z",
     "start_time": "2024-03-31T19:01:51.962854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "19"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dir = gt_fol\n",
    "\n",
    "gts = natsorted(os.listdir(gt_dir))\n",
    "\n",
    "skip_list = [\n",
    "    \"video-10-segment-1.csv\", \"video-9-segment-2.csv\"\n",
    "]\n",
    "\n",
    "gts = [x.split('.')[0] for x in gts if x.endswith('.csv') and int(x.split('-')[1])<=16 and x not in skip_list]#[:1]\n",
    "\n",
    "len(gts)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(\"/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/Images/video-14-segment-1-frame-14.jpeg\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:08:07.366526Z",
     "start_time": "2024-03-31T20:08:06.649644Z"
    }
   },
   "id": "586701401de4bab",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fc285aa-a396-470c-ba1f-b689a8d40540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T20:11:10.211900Z",
     "start_time": "2024-03-31T20:10:50.579082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there objects from the following list present in the image? Provide answers for all the objects in dictionary (without any newline(\\n)) format (i.e., {'car': 'yes'}). The object list includes: Accent Paving, Barrier Post, Barrier Stump, Bench, Bicycle, Bridge, Building, Bus, Bus Stop, Car, Chair, Closed Sidewalk, Counter, Crosswalk, Curb, Dog, Driveway(flat), Elevator, Escalator, Fence, Fire hydrant, Flush Door, Foldout Sign, Fountain, Gate, Guide dog, Gutter, Hose, Lamp Post, Mail box, Maintenance Vehicle, Motorcycle, Parallel Parking Spot, Paratransit vehicle, Pedestrian Crossing, Person, Person with a disability, Pillar, Pole, Puddle, Push button, Railing, Raised Entryway, Retaining Wall, Road, Road Divider, Road Shoulder, Roadside Parking, Sidewalk, Sidewalk pits, Sign, Sign Post, Sloped Driveway, Slopped Curb, Snow, Stairs, Stop sign, Street Vendor, Table, Tactile Paving, Traffic Signals, Train Platform, Train Tracks, Trash bins, Trash on roads, Tree, Turnstile, Uncontrolled Crossing, Uneven Stairs, Unpaved Road, Unpaved Sidewalk, Vegetation, Wall, Water leakage, Water Pipes, Wet surface, Wheelchair, White Cane, Yard Waste\n",
      "19.624385118484497\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"{'Accent Paving': 'no', 'Barrier Post': 'no', 'Barrier Stump': 'no', 'Bench': 'no', 'Bicycle': 'no', 'Bridge': 'no', 'Building': 'yes', 'Bus': 'no', 'Bus Stop': 'no', 'Car': 'yes', 'Chair': 'no', 'Closed Sidewalk': 'no', 'Counter': 'no', 'Crosswalk': 'no', 'Curb': 'yes', 'Dog': 'no', 'Driveway(flat)': 'no', 'Elevator': 'no', 'Escalator': 'no', 'Fence': 'yes', 'Fire hydrant': 'no', 'Flush Door': 'no', 'Foldout Sign': 'no', 'Fountain': 'no', 'Gate': 'yes', 'Guide dog': 'no', 'Gutter': 'no', 'Hose': 'no', 'Lamp Post': 'yes', 'Mail box': 'no', 'Maintenance Vehicle': 'no', 'Motorcycle': 'no', 'Parallel Parking Spot': 'no', 'Paratransit vehicle': 'no', 'Pedestrian Crossing': 'no', 'Person': 'yes', 'Person with a disability': 'yes', 'Pillar': 'no', 'Pole': 'no', 'Puddle': 'no', 'Push button': 'no', 'Railing': 'no', 'Raised Entryway': 'no', 'Retaining Wall': 'no', 'Road': 'yes', 'Road Divider': 'no', 'Road Shoulder': 'no', 'Roadside Parking': 'no', 'Sidewalk': 'yes', 'Sidewalk pits': 'no', 'Sign': 'yes', 'Sign Post': 'yes', 'Sloped Driveway': 'no', 'Slopped Curb': 'no', 'Snow': 'no', 'Stairs': 'no', 'Stop sign': 'no', 'Street Vendor': 'no', 'Table': 'no', 'Tactile Paving': 'no', 'Traffic Signals': 'no', 'Train Platform': 'no', 'Train Tracks': 'no', 'Trash bins': 'no', 'Trash on roads': 'no', 'Tree': 'yes', 'Turnstile': 'no', 'Uncontrolled Crossing': 'no', 'Uneven Stairs': 'no', 'Unpaved Road': 'no', 'Unpaved Sidewalk': 'no', 'Vegetation': 'yes', 'Wall': 'no', 'Water leakage': 'no', 'Water Pipes': 'no', 'Wet surface': 'no', 'Wheelchair': 'no', 'White Cane': 'yes', 'Yard Waste': 'no'}\""
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(que)\n",
    "s=time.time()\n",
    "image_path = \"/Users/ibk5106/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/Images/video-1-segment-4-frame-1.jpeg\"\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4-vision-preview\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": que\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 600\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "dict(response.json())['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12f7eb00-8c7a-4992-a742-cefbd1da1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt4v_raw_res_file = './gpt4v_out.json'\n",
    "# with open (gpt4v_raw_res_file, 'r') as f:\n",
    "#     gpt4v_raw_res = json.load(f)\n",
    "# gpt4v_raw_res['video-14-segment-1']['14'] = eval(dict(response.json())['choices'][0]['message']['content'])\n",
    "# import json\n",
    "\n",
    "# with open(\"gpt4v_out.json\", \"w\") as f: \n",
    "#     json.dump(gpt4v_raw_res, f, indent=4)\n",
    "# 36.35, 19, 22. 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c46ffb-4bc3-46a3-916f-afaf5c3e3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13d44946-026d-4a84-afbb-36e6994cceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image: video-16-segment-3-frame-10.jpeg\n",
      "got response\n",
      "current image: video-16-segment-3-frame-11.jpeg\n",
      "got response\n"
     ]
    }
   ],
   "source": [
    "for gt_ind, gt in enumerate(gts):\n",
    "    if gt not in result_dict.keys():\n",
    "        result_dict[gt] = {}\n",
    "        \n",
    "    images_tot = len(glob.glob(\n",
    "        os.path.join(\n",
    "            images_dir,\n",
    "            f'{gt}*'\n",
    "        )\n",
    "    ))\n",
    "    for i in range(images_tot):\n",
    "        if f'{i}' in result_dict[gt].keys():\n",
    "            continue\n",
    "        img_name = f'{gt}-frame-{i}.jpeg'\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        base64_image = encode_image(img_path)\n",
    "        payload = {\n",
    "          \"model\": \"gpt-4-vision-preview\",\n",
    "          \"messages\": [\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": [\n",
    "                {\n",
    "                  \"type\": \"text\",\n",
    "                  \"text\": que\n",
    "                },\n",
    "                {\n",
    "                  \"type\": \"image_url\",\n",
    "                  \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ],\n",
    "          \"max_tokens\": 600\n",
    "        }\n",
    "        print(f\"current image: {img_name}\")\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        try:\n",
    "            out = eval(dict(response.json())['choices'][0]['message']['content'])\n",
    "        except Exception as e:\n",
    "            print(response)\n",
    "            out = eval(dict(response.json())['choices'][0]['message']['content'])\n",
    "            \n",
    "        print(f\"got response\")\n",
    "        result_dict[gt][f'{i}'] = out\n",
    "            \n",
    "        time.sleep(5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c1614d9-e3c3-4191-9770-455ac67fd927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['video-16-segment-3'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e24a1992-4df4-401f-91a1-d73fb4e6ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"gpt4v_out.json\", \"w\") as f: \n",
    "    json.dump(result_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_pytorch] *",
   "language": "python",
   "name": "conda-env-conda_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
