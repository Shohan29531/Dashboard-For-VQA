{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:17.967421Z",
     "start_time": "2023-11-02T14:49:11.973119Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import lpips\n",
    "import math\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.linalg as linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imrankabir/Desktop/research/vqa_accessibility/Dashboard-For-VQA/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/imrankabir/Desktop/research/vqa_accessibility/Dashboard-For-VQA/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/imrankabir/Desktop/research/vqa_accessibility/Dashboard-For-VQA/venv/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imrankabir/Desktop/research/vqa_accessibility/Dashboard-For-VQA/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/imrankabir/Desktop/research/vqa_accessibility/Dashboard-For-VQA/venv/lib/python3.9/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "loss_fn_vgg = lpips.LPIPS(net='vgg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:18.908877Z",
     "start_time": "2023-11-02T14:49:17.967932Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "images_dir = '/Users/imrankabir/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data/Images'\n",
    "data_path = '/Users/imrankabir/Desktop/research/vqa_accessibility/Dashboard-For-VQA/Dashboard Data'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:18.911651Z",
     "start_time": "2023-11-02T14:49:18.909202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "transform_f = transforms.ToTensor()\n",
    "\n",
    "def normalize_image(in_img):\n",
    "    pixels = np.asarray(in_img).astype('float32')\n",
    "    pixels = (pixels - mean) / std\n",
    "    return pixels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:20.322410Z",
     "start_time": "2023-11-02T14:49:20.310852Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_steady_state_probabilities_ifs(pred, img_dir, vid_n, seg_n):\n",
    "    pred = pred.T\n",
    "    unq_st = np.unique(pred, axis=0)\n",
    "    unq_st_str = []\n",
    "    for x in unq_st:\n",
    "        str_bit = [str(ch) for ch in x]\n",
    "        unq_st_str.append(''.join(str_bit))\n",
    "\n",
    "    transition_matrix_dict = {\n",
    "        'st': [x for x in unq_st_str]\n",
    "    }\n",
    "    for u_s_s in unq_st_str:\n",
    "        transition_matrix_dict[u_s_s] = [0.0 for _ in unq_st_str]\n",
    "\n",
    "    transition_matrix = pd.DataFrame(transition_matrix_dict)\n",
    "    transition_matrix = transition_matrix.set_index('st')\n",
    "\n",
    "    for f in range(1, pred.shape[0]):\n",
    "        s_now = ''.join([str(ch) for ch in pred[f]])\n",
    "        s_prev = ''.join([str(ch) for ch in pred[f-1]])\n",
    "        f_now_pth = os.path.join(img_dir, f'video-{vid_n}-segment-{seg_n}-frame-{f}.jpeg')\n",
    "        f_prev_pth = os.path.join(img_dir, f'video-{vid_n}-segment-{seg_n}-frame-{f-1}.jpeg')\n",
    "\n",
    "        image_now = cv2.resize(normalize_image(np.array(Image.open(\n",
    "            f_now_pth\n",
    "        ).convert('RGB'))/255), (64, 64), interpolation = cv2.INTER_LINEAR).astype(np.float32)\n",
    "        image_prev = cv2.resize(normalize_image(np.array(Image.open(\n",
    "            f_prev_pth\n",
    "        ).convert('RGB'))/255), (64, 64), interpolation = cv2.INTER_LINEAR).astype(np.float32)\n",
    "\n",
    "        img0 = transform_f(image_now).unsqueeze(0)\n",
    "        img1 = transform_f(image_prev).unsqueeze(0)\n",
    "\n",
    "        d = loss_fn_alex(img0, img1).detach().numpy()[0,0,0,0]\n",
    "\n",
    "        transition_matrix[s_prev][s_prev] += (1.0*d)\n",
    "        transition_matrix[s_now][s_prev] += (1.0*(1-d))\n",
    "\n",
    "    for ind, row in transition_matrix.iterrows():\n",
    "        row = row/(row.sum()+1e-15)\n",
    "        transition_matrix.loc[ind] = row\n",
    "\n",
    "    transition_matrix = np.array(transition_matrix)\n",
    "\n",
    "    I = np.identity(transition_matrix.shape[0])\n",
    "    P_I = transition_matrix - I\n",
    "    co_eff = P_I.T\n",
    "\n",
    "    co_eff[co_eff.shape[0]-1] =  np.ones((co_eff.shape[1]))\n",
    "    const = np.array([0.0 for _ in range(co_eff.shape[0])])\n",
    "    const[const.shape[0]-1] = 1.0\n",
    "\n",
    "    p_s_ifs = np.linalg.solve(co_eff, const)\n",
    "\n",
    "    return p_s_ifs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:21.011968Z",
     "start_time": "2023-11-02T14:49:21.004303Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_steady_state_probabilities(h_m):\n",
    "    hm = np.array(h_m).T\n",
    "    unique_states = np.unique(hm, axis=0)\n",
    "    unq_st_and_count = {}\n",
    "    for i, u_s in enumerate(unique_states):\n",
    "        c = np.argwhere(np.all(hm == u_s, axis=-1)).shape[0]\n",
    "        unq_st_and_count[i] = {\n",
    "            'val': u_s,\n",
    "            'count': c,\n",
    "            'ss_prob': c/hm.shape[0]\n",
    "        }\n",
    "\n",
    "    return np.array([unq_st_and_count[k]['ss_prob'] for k in unq_st_and_count.keys()])\n",
    "\n",
    "\n",
    "def calculate_entropy(ss_probs):\n",
    "    if len(ss_probs) <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    tot_ss_ent = 0\n",
    "\n",
    "    for prb in ss_probs:\n",
    "        if prb == 0:\n",
    "            log_p_ss = 0\n",
    "        else:\n",
    "            log_p_ss = math.log2(prb)\n",
    "\n",
    "        t_ent = - prb * log_p_ss\n",
    "\n",
    "        tot_ss_ent = tot_ss_ent + t_ent\n",
    "\n",
    "    tot_ss_ent = tot_ss_ent / math.log2(len(ss_probs))\n",
    "\n",
    "    return tot_ss_ent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:21.963203Z",
     "start_time": "2023-11-02T14:49:21.953442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_st_p_ent(vid, seg, img_path, objs, model):\n",
    "    pred_file = os.path.join(\n",
    "        data_path,\n",
    "        f'{model}/video-{vid}-segment-{seg}.csv'\n",
    "    )\n",
    "    pred_df = pd.read_csv(pred_file)\n",
    "    pred_df = pred_df.transpose()\n",
    "    pred_df.columns = pred_df.iloc[0]\n",
    "    pred_df = pred_df.iloc[1:]\n",
    "    pred_df.columns = map(str.lower, pred_df.columns)\n",
    "    if\n",
    "    pred_df = pred_df.reindex(columns=objs).fillna('0').transpose()\n",
    "\n",
    "    p_steady_ifs = get_steady_state_probabilities_ifs(np.array(pred_df), images_dir, vid, seg)\n",
    "    ent_ifs = calculate_entropy(p_steady_ifs)\n",
    "\n",
    "    p_steady = get_steady_state_probabilities(np.array(pred_df))\n",
    "    ent = calculate_entropy(p_steady)\n",
    "\n",
    "    return p_steady, ent, p_steady_ifs, ent_ifs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:23.234143Z",
     "start_time": "2023-11-02T14:49:23.225832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "v_ = 2\n",
    "s_ = 1\n",
    "\n",
    "coco_common_obj = ['person', 'bicycle', 'car', 'motorcycle', 'bus', 'traffic signals', 'fire hydrant', 'stop sign'\n",
    "                   'bench', 'dog', 'chair', 'vegetation']\n",
    "\n",
    "pfb_common_obj = ['road', 'sidewalk', 'tree', 'vegetation', 'building', 'fence', 'traffic signals',\n",
    "                  'fire hydrant', 'chair', 'trash on roads', 'trash bins', 'person', 'car', 'motorcycle',\n",
    "                  'bus']\n",
    "\n",
    "ram_obj_map = {\n",
    "    'chair': 'chair',\n",
    "    'pillar': 'pillar',\n",
    "    'table': 'table',\n",
    "    'person': 'person',\n",
    "    'man': 'person',\n",
    "    'building': 'building',\n",
    "    'city street': 'road',\n",
    "    'curb': 'curb',\n",
    "    'pavement': 'sidewalk',\n",
    "    'road': 'road',\n",
    "    'car': 'car',\n",
    "    'snow': 'snow',\n",
    "    'doorway': 'sloped driveway',\n",
    "    'elevator': 'elevator',\n",
    "    'rail': 'train tracks',\n",
    "    'stair': 'stairs',\n",
    "    'cane': 'white cane',\n",
    "    'door': 'flush door',\n",
    "    'fence': 'fence',\n",
    "    'barrier': 'barrier post',\n",
    "    'bench': 'bench',\n",
    "    'sign': 'sign',\n",
    "    'bin': 'trash bins',\n",
    "    'pole': 'pole',\n",
    "    'street vendor': 'street vendor',\n",
    "    'blind': 'person with a disability',\n",
    "    'dog': 'dog',\n",
    "    'escalator': 'escalator',\n",
    "    'street sign': 'sign post',\n",
    "    'bus stop': 'bus stop',\n",
    "    'railway station': 'train platform',\n",
    "    'tree': 'tree',\n",
    "    'traffic light': 'traffic signals',\n",
    "    'tree trunk': 'tree',\n",
    "    'recycling bin': 'trash bins',\n",
    "    'train track': 'train tracks',\n",
    "    'pedestrian': 'person',\n",
    "    'bus': 'bus',\n",
    "    'city bus': 'bus',\n",
    "    'tour bus': 'bus',\n",
    "    'wall': 'wall',\n",
    "    'elevator door': 'elevator',\n",
    "    'bicycle': 'bicycle',\n",
    "    'crosswalk': 'crosswalk',\n",
    "    'decker bus': 'bus',\n",
    "    'motorcycle': 'motorcycle',\n",
    "    'motorcyclist': 'person',\n",
    "    'biker': 'person',\n",
    "    'motorbike': 'motorcycle',\n",
    "    'warning sign': 'sign',\n",
    "    'hydrant': 'fire hydrant',\n",
    "    'school bus': 'bus',\n",
    "    'vegetation': 'vegetation',\n",
    "    'fountain': 'fountain'\n",
    "}\n",
    "\n",
    "ram_com_obj = list(set(list(ram_obj_map.values())))\n",
    "\n",
    "print(len(ram_com_obj))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:24.696417Z",
     "start_time": "2023-11-02T14:49:24.693144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1875     0.02083333 0.02083333 0.02083333 0.02083333 0.02083333\n",
      " 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333\n",
      " 0.02083333 0.04166667 0.02083333 0.02083333 0.02083333 0.02083333\n",
      " 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333\n",
      " 0.02083333 0.04166667 0.02083333 0.04166667 0.02083333 0.04166667\n",
      " 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333] 0.9330763782720773\n",
      "[ 0.30461255 -0.          0.02713445  0.01981485 -0.         -0.\n",
      "  0.0328566  -0.          0.021557    0.03153359  0.02516728 -0.\n",
      " -0.          0.04254843  0.03399764  0.0240102   0.02180371  0.0325708\n",
      "  0.02595691  0.03384455 -0.         -0.         -0.         -0.\n",
      " -0.          0.04606739  0.04061     0.04204952 -0.          0.04825959\n",
      "  0.03649742  0.0332447   0.02127787  0.0217299  -0.          0.03285506] 0.7646642432775831\n"
     ]
    }
   ],
   "source": [
    "model_ = 'BLIP'\n",
    "p_s, e_, p_s_i, e_i = get_st_p_ent(v_, s_, images_dir, ram_com_obj, model_)\n",
    "print(p_s, e_)\n",
    "print(p_s_i, e_i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:49:40.364008Z",
     "start_time": "2023-11-02T14:49:37.354514Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0625     0.02083333 0.02083333 0.02083333 0.02083333 0.02083333\n",
      " 0.02083333 0.04166667 0.02083333 0.02083333 0.02083333 0.02083333\n",
      " 0.02083333 0.04166667 0.02083333 0.02083333 0.02083333 0.04166667\n",
      " 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333\n",
      " 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333\n",
      " 0.02083333 0.02083333 0.02083333 0.04166667 0.02083333 0.02083333\n",
      " 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333 0.02083333] 0.9864470617566723\n",
      "[ 0.09878198  0.05248973  0.03274158  0.0314793   0.03711434 -0.\n",
      "  0.04208139  0.06598613  0.03898865  0.03435076 -0.          0.05248774\n",
      " -0.          0.06521239  0.03299874  0.05155746 -0.          0.0714435\n",
      " -0.         -0.         -0.          0.03343162 -0.          0.03072981\n",
      " -0.         -0.         -0.         -0.          0.06297991 -0.\n",
      "  0.03369976 -0.         -0.          0.07484327 -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.          0.05660194] 0.7848963529233669\n"
     ]
    }
   ],
   "source": [
    "model_ = 'GPV-1'\n",
    "p_s, e_, p_s_i, e_i = get_st_p_ent(v_, s_, images_dir, ram_com_obj, model_)\n",
    "print(p_s, e_)\n",
    "print(p_s_i, e_i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:50:04.678081Z",
     "start_time": "2023-11-02T14:50:01.952015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.04166667 0.04166667 0.02083333 0.02083333 0.02083333\n",
      " 0.0625     0.02083333 0.02083333 0.02083333 0.02083333 0.04166667] 0.5655760724651602\n",
      "[0.66962948 0.03068688 0.04943406 0.02161422 0.02075942 0.02310563\n",
      " 0.06199445 0.02179995 0.02180388 0.0219827  0.02028933 0.03689999] 0.562771966998245\n"
     ]
    }
   ],
   "source": [
    "model_ = 'RAM'\n",
    "p_s, e_, p_s_i, e_i = get_st_p_ent(v_, s_, images_dir, ram_com_obj, model_)\n",
    "print(p_s, e_)\n",
    "print(p_s_i, e_i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:50:36.789886Z",
     "start_time": "2023-11-02T14:50:34.044039Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
